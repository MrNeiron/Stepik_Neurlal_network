{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-e155f318c0d5>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-e155f318c0d5>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    def __init__(self, weights, activation_function''' = активационная функция''', activation_function_derivative ''' = производная активационной функции'''):\u001b[0m\n\u001b[1;37m                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as p3\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from functools import partial\n",
    "from ipywidgets import interact, RadioButtons, IntSlider, FloatSlider, Dropdown, BoundedFloatText\n",
    "from numpy.linalg import norm\n",
    "\n",
    "random.seed(42) # начальное состояние генератора случайных чисел, чтобы можно было воспроизводить результаты.\n",
    "    \n",
    "\n",
    "class Neuron:\n",
    "\n",
    "    def __init__(self, weights, activation_function''' = активационная функция''', activation_function_derivative ''' = производная активационной функции'''):\n",
    "        \n",
    "        assert weights.shape[1] == 1, \"Incorrect weight shape\"\n",
    "        \n",
    "        self.w = weights\n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_derivative = activation_function_derivative\n",
    "        \n",
    "\n",
    "    #Рассчет предсказанных значений без векторизации(хуже способ)\n",
    "    def forward_pass(self, single_input):\n",
    "        \n",
    "        result = 0\n",
    "        for i in range(self.w.size):\n",
    "            result += float(self.w[i] * single_input[i])\n",
    "        return self.activation_function(result)\n",
    "    \n",
    "    '''summatory = lambda p,x: x @ p.w'''\n",
    "    \n",
    "    #Сумматорный метод\n",
    "    def summatory(self, input_matrix):\n",
    "        return input_matrix.dot(self.w)\n",
    "    \n",
    "    '''activation = lambda p,x: p.activation_function(x)'''\n",
    "    \n",
    "    #Активационный метод\n",
    "    def activation(self, summatory_activation):\n",
    "        return self.activation_function(summatory_activation)\n",
    "    \n",
    "    '''vectorized_forward_pass = lambda p,x: p.activation(p.summatory(x))'''\n",
    "    \n",
    "    #Векторизованный метод рассчета предсказанных значений(гораздо лучший способ)\n",
    "    def vectorized_forward_pass(self, input_matrix):\n",
    "        return self.activation(self.summatory(input_matrix))\n",
    "\n",
    "    '''def update_mini_batch(self, X, y, learning_rate, eps):\n",
    "        \n",
    "        before = 0.5 * np.mean((self.vectorized_forward_pass(X) - y)**2)\n",
    "        \n",
    "        sigma = self.vectorized_forward_pass(X)\n",
    "        \n",
    "        grad = (((sigma - y)/len(y) * self.activation_function_derivative(self.summatory(X))).T.dot(X)).T\n",
    "        \n",
    "        self.w -= learning_rate*grad\n",
    "        \n",
    "        return np.abs(before - (0.5 * np.mean((self.vectorized_forward_pass(X) - y)**2))) < eps'''\n",
    "    \n",
    "    \n",
    "    #Обучение весов с помощью одного батча(несколько случайных примеров из всех имеющихся примеров)\n",
    "    def update_mini_batch(self, X, y, learning_rate, eps):\n",
    "        \n",
    "        before = J_quadratic(self, X, y)\n",
    "        \n",
    "        #self.w -= learning_rate * compute_grad_analytically(self,X,y)\n",
    "        self.w -= learning_rate * compute_grad_numerically_2(self,X,y)\n",
    "\n",
    "        \n",
    "        return np.abs(before-J_quadratic(self, X, y)) < eps\n",
    "    \n",
    "    \n",
    "    #Обучение весов с помощью батчей\n",
    "    def SGD(self, X, y, batch_size, learning_rate =0.1, eps=1e-6, max_steps = 200):\n",
    "        cur_step = 0\n",
    "        #for _ in range(max_steps):\n",
    "        while cur_step < max_steps:\n",
    "            cur_step += 1\n",
    "            batch = np.random.choice(len(X), batch_size, replace = False)\n",
    "            if self.update_mini_batch(X[batch], y[batch], learning_rate, eps) == 1: \n",
    "                return 1\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
