{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cars'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f24051293edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlearning_algorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cars'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from cars.utils import Action\n",
    "from learning_algorithms.network import Network\n",
    "\n",
    "\n",
    "class Agent(metaclass=ABCMeta):\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def rays(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def choose_action(self, sensor_info):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def receive_feedback(self, reward):\n",
    "        pass\n",
    "\n",
    "\n",
    "class SimpleCarAgent(Agent):\n",
    "    def __init__(self, history_data=int(50000)):\n",
    "        \"\"\"\n",
    "        Создаёт машинку\n",
    "        :param history_data: количество хранимых нами данных о результатах предыдущих шагов\n",
    "        \"\"\"\n",
    "        self.evaluate_mode = False  # этот агент учится или экзаменутеся? если учится, то False\n",
    "        self._rays =  5# выберите число лучей ладара; например, 5\n",
    "        # here +2 is for 2 inputs from elements of Action that we are trying to predict\n",
    "        self.neural_net = Network([self.rays + 4,\n",
    "                                   # внутренние слои сети: выберите, сколько и в каком соотношении вам нужно\n",
    "                                   # например, (self.rays + 4) * 2 или просто число\n",
    "                                   1],\n",
    "                                  output_function=lambda x: x, output_derivative=lambda x: 1)\n",
    "        self.sensor_data_history = deque([], maxlen=history_data)\n",
    "        self.chosen_actions_history = deque([], maxlen=history_data)\n",
    "        self.reward_history = deque([], maxlen=history_data)\n",
    "        self.step = 0\n",
    "\n",
    "    @classmethod\n",
    "    def from_weights(cls, layers, weights, biases):\n",
    "        \"\"\"\n",
    "        Создание агента по параметрам его нейронной сети. Разбираться не обязательно.\n",
    "        \"\"\"\n",
    "        agent = SimpleCarAgent()\n",
    "        agent._rays = weights[0].shape[1] - 4\n",
    "        nn = Network(layers, output_function=lambda x: x, output_derivative=lambda x: 1)\n",
    "\n",
    "        if len(weights) != len(nn.weights):\n",
    "            raise AssertionError(\"You provided %d weight matrices instead of %d\" % (len(weights), len(nn.weights)))\n",
    "        for i, (w, right_w) in enumerate(zip(weights, nn.weights)):\n",
    "            if w.shape != right_w.shape:\n",
    "                raise AssertionError(\"weights[%d].shape = %s instead of %s\" % (i, w.shape, right_w.shape))\n",
    "        nn.weights = weights\n",
    "\n",
    "        if len(biases) != len(nn.biases):\n",
    "            raise AssertionError(\"You provided %d bias vectors instead of %d\" % (len(weights), len(nn.weights)))\n",
    "        for i, (b, right_b) in enumerate(zip(biases, nn.biases)):\n",
    "            if b.shape != right_b.shape:\n",
    "                raise AssertionError(\"biases[%d].shape = %s instead of %s\" % (i, b.shape, right_b.shape))\n",
    "        nn.biases = biases\n",
    "\n",
    "        agent.neural_net = nn\n",
    "\n",
    "        return agent\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, s):\n",
    "        from numpy import array  # это важный импорт, без него не пройдёт нормально eval\n",
    "        layers, weights, biases = eval(s.replace(\"\\n\", \"\"), locals())\n",
    "        return cls.from_weights(layers, weights, biases)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, filename):\n",
    "        c = open(filename, \"r\").read()\n",
    "        return cls.from_string(c)\n",
    "\n",
    "    def show_weights(self):\n",
    "        params = self.neural_net.sizes, self.neural_net.weights, self.neural_net.biases\n",
    "        np.set_printoptions(threshold=np.nan)\n",
    "        return repr(params)\n",
    "\n",
    "    def to_file(self, filename):\n",
    "        c = self.show_weights()\n",
    "        f = open(filename, \"w\")\n",
    "        f.write(c)\n",
    "        f.close()\n",
    "\n",
    "    @property\n",
    "    def rays(self):\n",
    "        return self._rays\n",
    "\n",
    "    def choose_action(self, sensor_info):\n",
    "        # хотим предсказать награду за все действия, доступные из текущего состояния\n",
    "        rewards_to_controls_map = {}\n",
    "        # дискретизируем множество значений, так как все возможные мы точно предсказать не сможем\n",
    "        for steering in np.linspace(-1, 1, 3):  # выбирать можно и другую частоту дискретизации, но\n",
    "            for acceleration in np.linspace(-0.75, 0.75, 3):  # в наших тестах будет именно такая\n",
    "                action = Action(steering, acceleration)\n",
    "                agent_vector_representation = np.append(sensor_info, action)\n",
    "                agent_vector_representation = agent_vector_representation.flatten()[:, np.newaxis]\n",
    "                predicted_reward = float(self.neural_net.feedforward(agent_vector_representation))\n",
    "                rewards_to_controls_map[predicted_reward] = action\n",
    "\n",
    "        # ищем действие, которое обещает максимальную награду\n",
    "        rewards = list(rewards_to_controls_map.keys())\n",
    "        highest_reward = max(rewards)\n",
    "        best_action = rewards_to_controls_map[highest_reward]\n",
    "\n",
    "        # Добавим случайности, дух авантюризма. Иногда выбираем совершенно\n",
    "        # рандомное действие\n",
    "        if (not self.evaluate_mode) and (random.random() < 0.05):\n",
    "            highest_reward = rewards[np.random.choice(len(rewards))]\n",
    "            best_action = rewards_to_controls_map[highest_reward]\n",
    "        # следующие строки помогут вам понять, что предсказывает наша сеть\n",
    "        #     print(\"Chosen random action w/reward: {}\".format(highest_reward))\n",
    "        # else:\n",
    "        #     print(\"Chosen action w/reward: {}\".format(highest_reward))\n",
    "\n",
    "        # запомним всё, что только можно: мы хотим учиться на своих ошибках\n",
    "        self.sensor_data_history.append(sensor_info)\n",
    "        self.chosen_actions_history.append(best_action)\n",
    "        self.reward_history.append(0.0)  # мы пока не знаем, какая будет награда, это\n",
    "        # откроется при вызове метода receive_feedback внешним миром\n",
    "\n",
    "        return best_action\n",
    "\n",
    "    def receive_feedback(self, reward, train_every=50, reward_depth=7):\n",
    "        \"\"\"\n",
    "        Получить реакцию на последнее решение, принятое сетью, и проанализировать его\n",
    "        :param reward: оценка внешним миром наших действий\n",
    "        :param train_every: сколько нужно собрать наблюдений, прежде чем запустить обучение на несколько эпох\n",
    "        :param reward_depth: на какую глубину по времени распространяется полученная награда\n",
    "        \"\"\"\n",
    "        # считаем время жизни сети; помогает отмерять интервалы обучения\n",
    "        self.step += 1\n",
    "\n",
    "        # начиная с полной полученной истинной награды,\n",
    "        # размажем её по предыдущим наблюдениям\n",
    "        # чем дальше каждый раз домножая её на 1/2\n",
    "        # (если мы врезались в стену - разумно наказывать не только последнее\n",
    "        # действие, но и предшествующие)\n",
    "        i = -1\n",
    "        while len(self.reward_history) > abs(i) and abs(i) < reward_depth:\n",
    "            self.reward_history[i] += reward\n",
    "            reward *= 0.5\n",
    "            i -= 1\n",
    "\n",
    "        # Если у нас накопилось хоть чуть-чуть данных, давайте потренируем нейросеть\n",
    "        # прежде чем собирать новые данные\n",
    "        # (проверьте, что вы в принципе храните достаточно данных (параметр `history_data` в `__init__`),\n",
    "        # чтобы условие len(self.reward_history) >= train_every выполнялось\n",
    "        if not self.evaluate_mode and (len(self.reward_history) >= train_every) and not (self.step % train_every):\n",
    "            X_train = np.concatenate([self.sensor_data_history, self.chosen_actions_history], axis=1)\n",
    "            y_train = self.reward_history\n",
    "            train_data = [(x[:, np.newaxis], y) for x, y in zip(X_train, y_train)]\n",
    "            self.neural_net.SGD(training_data=train_data, epochs=15, mini_batch_size=train_every, eta=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
