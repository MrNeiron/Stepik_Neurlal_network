{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e119b319611a4cc891c343f1e238f7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=0.0, description='Enter $b$:', max=40.0, min=-40.0), BoundedFloat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73526b24c6844bc966790883477e50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, continuous_update=False, description='fixed_bias', max=40.0, min=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as p3\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from ipywidgets import interact, RadioButtons, IntSlider, FloatSlider, Dropdown, BoundedFloatText\n",
    "from numpy.linalg import norm\n",
    "\n",
    "random.seed(42) # начальное состояние генератора случайных чисел, чтобы можно было воспроизводить результаты.\n",
    "\n",
    "#Активационная функция сигмоидального нейрона\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "#Производная активационной функции сигмоидального нейрона\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "#Считает целевую функциюю\n",
    "def J_quadratic(neuron, X, y):\n",
    "    \"\"\"\n",
    "    Оценивает значение квадратичной целевой функции.\n",
    "    Всё как в лекции, никаких хитростей.\n",
    "\n",
    "    neuron - нейрон, у которого есть метод vectorized_forward_pass, предсказывающий значения на выборке X\n",
    "    X - матрица входных активаций (n, m)\n",
    "    y - вектор правильных ответов (n, 1)\n",
    "\n",
    "    Возвращает значение J (число)\n",
    "    \"\"\"\n",
    "\n",
    "    assert y.shape[1] == 1, 'Incorrect y shape'\n",
    "\n",
    "    return 0.5 * np.mean((neuron.vectorized_forward_pass(X) - y) ** 2)\n",
    "def J_by_weights(weights, X, y, bias):\n",
    "    \"\"\"\n",
    "    Посчитать значение целевой функции для нейрона с заданными весами.\n",
    "    Только для визуализации\n",
    "    \"\"\"\n",
    "    new_w = np.hstack((bias, weights)).reshape((3,1))\n",
    "    return J_quadratic(Neuron(new_w), X, y)\n",
    "\n",
    "\n",
    "\n",
    "#Провера градиента(численная производная целевой функции)\n",
    "def compute_grad_numerically_2(neuron, X, y, J=J_quadratic, eps=10e-2):\n",
    "    \n",
    "    w_0 = neuron.w\n",
    "    num_grad = np.zeros(neuron.w.shape)\n",
    "\n",
    "    for i in range(len(neuron.w)):\n",
    "        \n",
    "        for k in range(-1,2,2):\n",
    "            \n",
    "            oldW = neuron.w[i,0]\n",
    "            neuron.w[i] += eps*k\n",
    "            num_grad[i] += J(neuron, X, y)*k\n",
    "            neuron.w[i,0] = oldW\n",
    "        \n",
    "    assert np.allclose(neuron.w, w_0), \"WE SPOILED THE WEIGHT\"\n",
    "    return num_grad/(2*eps)\n",
    "\n",
    "   \n",
    "class Neuron:\n",
    "\n",
    "    def __init__(self, weights, activation_function=sigmoid, activation_function_derivative = sigmoid_prime):\n",
    "        \n",
    "        assert weights.shape[1] == 1, \"Incorrect weight shape\"\n",
    "        \n",
    "        self.w = weights\n",
    "        self.activation_function = activation_function\n",
    "        self.activation_function_derivative = activation_function_derivative\n",
    "    \n",
    "    #Сумматорный метод\n",
    "    def summatory(self, input_matrix):\n",
    "        return input_matrix.dot(self.w)\n",
    "    \n",
    "    \n",
    "    #Активационный метод\n",
    "    def activation(self, summatory_activation):\n",
    "        return self.activation_function(summatory_activation)\n",
    "    \n",
    "    \n",
    "    #Векторизованный метод рассчета предсказанных значений(гораздо лучший способ)\n",
    "    def vectorized_forward_pass(self, input_matrix):\n",
    "        return self.activation(self.summatory(input_matrix))\n",
    "\n",
    "    \n",
    "    #Обучение весов с помощью одного батча(несколько случайных примеров из всех имеющихся примеров)\n",
    "    def update_mini_batch(self, X, y, learning_rate, eps):\n",
    "        \n",
    "        before = J_quadratic(self, X, y)\n",
    "        \n",
    "        #self.w -= learning_rate * compute_grad_analytically(self,X,y)\n",
    "        self.w -= learning_rate * compute_grad_numerically_2(self,X,y)\n",
    "\n",
    "        \n",
    "        return np.abs(before-J_quadratic(self, X, y)) < eps\n",
    "    \n",
    "    \n",
    "    #Обучение весов с помощью батчей\n",
    "    def SGD(self, X, y, batch_size, learning_rate =0.1, eps=1e-6, max_steps = 200):\n",
    "        cur_step = 0\n",
    "        #for _ in range(max_steps):\n",
    "        while cur_step < max_steps:\n",
    "            cur_step += 1\n",
    "            batch = np.random.choice(len(X), batch_size, replace = False)\n",
    "            if self.update_mini_batch(X[batch], y[batch], learning_rate, eps) == 1: \n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Загрузка данных из файла\n",
    "data = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
    "\n",
    "# Подготовим данные\n",
    "\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "X = np.hstack((np.ones((len(y), 1)), X))\n",
    "y = y.reshape((len(y), 1)) # Обратите внимание на эту очень противную и важную строчку\n",
    "\n",
    "\n",
    "# Создадим нейрон\n",
    "\n",
    "w = np.random.random((X.shape[1], 1))\n",
    "neuron = Neuron(w, activation_function=sigmoid, activation_function_derivative=sigmoid_prime)\n",
    "\n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "#point = (neuron.w[1,0], neuron.w[2,0])\n",
    "point = (0,20)\n",
    "redPoint = (point[0], point[1], J_by_weights(point, X, y, 0.0))\n",
    "max_b = 40\n",
    "min_b = -40\n",
    "max_w1 = 40\n",
    "min_w1 = -40\n",
    "max_w2 = 40\n",
    "min_w2 = -40\n",
    "\n",
    "g_bias = 0 # график номер 2 будет при первой генерации по умолчанию иметь то значение b, которое выставлено в первом\n",
    "X_corrupted = X.copy()\n",
    "y_corrupted = y.copy()\n",
    "\n",
    "\n",
    "\n",
    "#Начало реализации истории обучения \n",
    "@interact(b=BoundedFloatText(value=str(g_bias), min=min_b, max=max_b, description=\"Enter $b$:\"),\n",
    "          w1=BoundedFloatText(value=redPoint[0], min=min_w1, max=max_w1, description=\"Enter $w_1$:\"),\n",
    "          w2=BoundedFloatText(value=redPoint[1], min=min_w2, max=max_w2, description=\"Enter $w_2$:\"),\n",
    "          learning_rate=Dropdown(options=[\"0.01\", \"0.05\", \"0.1\", \"0.5\", \"1\", \"5\", \"10\"], \n",
    "                                value=\"10\", description=\"Learning rate: \")\n",
    "         )\n",
    "def learning_curve_for_starting_point(b, w1, w2, learning_rate=0.1):\n",
    "    w = np.array([b, w1, w2]).reshape(X_corrupted.shape[1], 1)\n",
    "    learning_rate=float(learning_rate)\n",
    "    neuron = Neuron(w, activation_function=sigmoid, activation_function_derivative=sigmoid_prime)\n",
    "\n",
    "    story = [J_quadratic(neuron, X_corrupted, y_corrupted)]\n",
    "    for _ in range(2000):\n",
    "        neuron.SGD(X_corrupted, y_corrupted, 2, learning_rate=learning_rate, max_steps=2)\n",
    "        story.append(J_quadratic(neuron, X_corrupted, y_corrupted))\n",
    "    plt.plot(story)\n",
    "    \n",
    "    plt.title(\"Learning curve.\\n Final $b={0:.3f}$, $w_1={1:.3f}, w_2={2:.3f}$\".format(*neuron.w.ravel()))\n",
    "    plt.ylabel(\"$J(w_1, w_2)$\")\n",
    "    plt.xlabel(\"Weight and bias update number\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#Начало визуализации целевой функции\n",
    "@interact(fixed_bias=FloatSlider(min=min_b, max=max_b, continuous_update=False), \n",
    "          mixing=FloatSlider(min=0, max=1, continuous_update=False, value=0),\n",
    "          shifting=FloatSlider(min=0, max=1, continuous_update=False, value=0),\n",
    "          w1n=FloatSlider(min=-40, max=40, continuous_update=False, value=neuron.w[1,0]),\n",
    "          w2n=FloatSlider(min=-40, max=40, continuous_update=False, value=neuron.w[2,0]),\n",
    "         )\n",
    "def visualize_cost_function(fixed_bias, mixing, shifting, w1n, w2n):\n",
    "    \"\"\"\n",
    "    Визуализируем поверхность целевой функции на (опционально) подпорченных данных и сами данные.\n",
    "    Портим данные мы следующим образом: сдвигаем категории навстречу друг другу, на величину, равную shifting \n",
    "    Кроме того, меняем классы некоторых случайно выбранных примеров на противоположнее.\n",
    "    Доля таких примеров задаётся переменной mixing\n",
    "    \n",
    "    Нам нужно зафиксировать bias на определённом значении, чтобы мы могли что-нибудь визуализировать.\n",
    "    Можно посмотреть, как bias влияет на форму целевой функции\n",
    "    \"\"\"\n",
    "\n",
    "    xlim = (min_w1, max_w1)\n",
    "    ylim = (min_w2, max_w2)\n",
    "    xx = np.linspace(*xlim, num=101)\n",
    "    yy = np.linspace(*ylim, num=101)\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    "    points = np.stack([xx, yy], axis=2)\n",
    "    \n",
    "    # не будем портить исходные данные, будем портить их копию\n",
    "    corrupted = data.copy()\n",
    "    \n",
    "    # инвертируем ответы для случайно выбранного поднабора данных\n",
    "    mixed_subset = np.random.choice(range(len(corrupted)), int(mixing * len(corrupted)), replace=False)\n",
    "    corrupted[mixed_subset, -1] = np.logical_not(corrupted[mixed_subset, -1])\n",
    "    \n",
    "    # сдвинем все груши (внизу справа) на shifting наверх и влево\n",
    "    pears = corrupted[:, 2] == 1\n",
    "    apples = np.logical_not(pears)\n",
    "    corrupted[pears, 0] -= shifting\n",
    "    corrupted[pears, 1] += shifting\n",
    "    \n",
    "    # вытащим наружу испорченные данные\n",
    "    global X_corrupted, y_corrupted\n",
    "    X_corrupted = np.hstack((np.ones((len(corrupted),1)), corrupted[:, :-1]))\n",
    "    y_corrupted = corrupted[:, -1].reshape((len(corrupted), 1))\n",
    "    \n",
    "    \n",
    "    #point = (neuron.w[1,0], neuron.w[2,0])\n",
    "    bluePoint = (point[0], point[1], J_by_weights(point, X_corrupted, y_corrupted, fixed_bias))\n",
    "    redPoint = (w1n, w2n, J_by_weights((w1n,w2n), X_corrupted, y_corrupted, fixed_bias))\n",
    "    # посчитаем значения целевой функции на наших новых данных\n",
    "    calculate_weights = partial(J_by_weights, X=X_corrupted, y=y_corrupted, bias=fixed_bias)\n",
    "    J_values = np.apply_along_axis(calculate_weights, -1, points)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,5))\n",
    "    # сначала 3D-график целевой функции\n",
    "    ax_1 = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    surf = ax_1.plot_surface(xx, yy, J_values, alpha=0.3)\n",
    "    ax_1.plot_wireframe(xx, yy, J_values, rcount=11, ccount=11, color = \"black\")\n",
    "    ax_1.scatter(redPoint[0], redPoint[1], redPoint[2],  s = 200, color = \"red\", edgecolors = \"b\")\n",
    "    ax_1.scatter(bluePoint[0], bluePoint[1], bluePoint[2],  s = 200, color = \"blue\", edgecolors = \"b\")\n",
    "    ax_1.set_xlabel(\"$w_1$\")\n",
    "    ax_1.set_ylabel(\"$w_2$\")\n",
    "    ax_1.set_zlabel(\"$J(w_1, w_2)$\")\n",
    "    ax_1.set_title(\"$J(w_1, w_2)$ for fixed bias = ${}$\".format(fixed_bias))\n",
    "    # потом плоский поточечный график повреждённых данных\n",
    "    ax_2 = fig.add_subplot(1, 2, 2)\n",
    "    plt.scatter(corrupted[apples][:, 0], corrupted[apples][:, 1], color = \"red\", alpha=0.7)\n",
    "    plt.scatter(corrupted[pears][:, 0], corrupted[pears][:, 1], color = \"green\", alpha=0.7)\n",
    "    ax_2.set_xlabel(\"yellowness\")\n",
    "    ax_2.set_ylabel(\"symmetry\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
